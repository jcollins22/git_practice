{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 21 columns):\n",
      "id               21597 non-null int64\n",
      "date             21597 non-null object\n",
      "price            21597 non-null float64\n",
      "bedrooms         21597 non-null int64\n",
      "bathrooms        21597 non-null float64\n",
      "sqft_living      21597 non-null int64\n",
      "sqft_lot         21597 non-null int64\n",
      "floors           21597 non-null float64\n",
      "waterfront       19221 non-null float64\n",
      "view             21534 non-null float64\n",
      "condition        21597 non-null int64\n",
      "grade            21597 non-null int64\n",
      "sqft_above       21597 non-null int64\n",
      "sqft_basement    21597 non-null object\n",
      "yr_built         21597 non-null int64\n",
      "yr_renovated     17755 non-null float64\n",
      "zipcode          21597 non-null int64\n",
      "lat              21597 non-null float64\n",
      "long             21597 non-null float64\n",
      "sqft_living15    21597 non-null int64\n",
      "sqft_lot15       21597 non-null int64\n",
      "dtypes: float64(8), int64(11), object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#import data file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sqft_basement\"].replace(to_replace=\"?\", value=\"0.0\", inplace=True) #fix placeholders\n",
    "df[\"sqft_basement\"] = df[\"sqft_basement\"].astype(float, inplace=True) #reassign to float\n",
    "df[\"basement\"] = df[\"sqft_basement\"].apply(lambda x: False if x == 0.0 else True) #create a boolean variable\n",
    "df[\"yr_renovated\"].fillna(value = 0) #deal with missing data\n",
    "df[\"renovated\"] = df[\"yr_renovated\"].map(lambda x: x > 0, True) #boolean feature\n",
    "df[\"age_of_house\"] = 2019 - df[\"yr_built\"] #engineer feature\n",
    "df[\"upstairs_as_percent_of_house\"] = (df[\"sqft_living\"] - df[\"sqft_basement\"]) / df[\"sqft_living\"] #new feature\n",
    "df[\"bath_per_bed\"] = df[\"bathrooms\"] / df[\"bedrooms\"] #new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating helpful lists\n",
    "high_price_zipcodes = [98039, 98040, 98004, 98112]\n",
    "midhigh_price_zipcodes = [98075, 98033, 98074, 98053, 98121, 98006, 98199]\n",
    "mid_price_zipcodes = [98105, 98065, 98177, 98005, 98052, 98029, 98119, 98027 ,98072]\n",
    "top_20_zipcodes = high_price_zipcodes + midhigh_price_zipcodes + mid_price_zipcodes\n",
    "\n",
    "#creating a zipcode rank feature\n",
    "zipcode_rank = []\n",
    "\n",
    "for zipcode in df.zipcode:\n",
    "    if zipcode in set(high_price_zipcodes):\n",
    "        zipcode_rank.append(\"high\")        \n",
    "for zipcode in df.zipcode:\n",
    "    if zipcode in set(midhigh_price_zipcodes):\n",
    "        zipcode_rank.append(\"midhigh\")       \n",
    "for zipcode in df.zipcode:\n",
    "    if zipcode in set(mid_price_zipcodes):\n",
    "        zipcode_rank.append(\"mid\")\n",
    "for zipcode in df.zipcode:\n",
    "    if zipcode not in set(top_20_zipcodes):\n",
    "        zipcode_rank.append(\"other\")\n",
    "\n",
    "df[\"zipcode_rank\"] = zipcode_rank\n",
    "\n",
    "#recoding for final transform\n",
    "zipcode_recode = []\n",
    "for i in df[\"zipcode_rank\"]:\n",
    "    if i == \"high\":\n",
    "        zipcode_recode.append(3)\n",
    "    elif i == \"midhigh\":\n",
    "        zipcode_recode.append(2)\n",
    "    elif i == \"mid\":\n",
    "        zipcode_recode.append(1)\n",
    "    else:\n",
    "        zipcode_recode.append(0)\n",
    "df[\"zipcode_recode\"] = zipcode_recode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dummy variables\n",
    "\n",
    "bathroom_bins = [0, 2, 4, 8]\n",
    "df[\"bath_bin\"] = pd.cut(df[\"bathrooms\"], bathroom_bins)\n",
    "df.bath_bin.value_counts()\n",
    "\n",
    "bedroom_bins = [0, 2, 3, 5, 33]\n",
    "df[\"bed_bin\"] = pd.cut(df[\"bedrooms\"], bedroom_bins)\n",
    "df.bed_bin.value_counts()\n",
    "\n",
    "bed_dummy = pd.get_dummies(df.bed_bin, prefix=\"BED\")\n",
    "bath_dummy = pd.get_dummies(df.bath_bin, prefix=\"BATH\")\n",
    "df = pd.concat([df, bed_dummy, bath_dummy], axis=1)\n",
    "\n",
    "condition_bin = [0, 1, 2, 3, 4, 5]\n",
    "df[\"condition_bin\"] = pd.cut(df[\"condition\"], condition_bin)\n",
    "condition_dummy = pd.get_dummies(df.condition_bin, prefix=\"COND\")\n",
    "df = pd.concat([df, condition_dummy], axis=1)\n",
    "\n",
    "floor_bins = [0, 1, 2, 3, 4]\n",
    "df[\"floor_bin\"] = pd.cut(df[\"floors\"], floor_bins)\n",
    "floor_dummy = pd.get_dummies(df.floor_bin, prefix=\"FLOORS\")\n",
    "df = pd.concat([df, floor_dummy], axis=1)\n",
    "\n",
    "zip_bin = [0, 1, 2, 3]\n",
    "df[\"zip_bin\"] = pd.cut(df[\"zipcode_recode\"], zip_bin)\n",
    "zip_dummy = pd.get_dummies(df.zip_bin, prefix=\"ZIP\")\n",
    "df = pd.concat([df, zip_dummy], axis=1)\n",
    "\n",
    "view_bins = [0, 1, 2, 3, 4, 5]\n",
    "df[\"view_bin\"] = pd.cut(df[\"view\"], view_bins)\n",
    "view_dummy = pd.get_dummies(df.view_bin, prefix=\"VIEW\")\n",
    "df = pd.concat([df, view_dummy], axis=1)\n",
    "\n",
    "grade_bins = [1, 3, 7, 11, 13]\n",
    "df[\"grade_bin\"] = pd.cut(df[\"grade\"], grade_bins)\n",
    "grade_dummy = pd.get_dummies(df.grade_bin, prefix=\"GRADE\")\n",
    "df = pd.concat([df, grade_dummy], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable transforms for normality\n",
    "\n",
    "df[\"log_sqft_living15\"] = np.log(df.sqft_living15)\n",
    "df['log_sqft_lot15'] = np.log(df.sqft_lot15)\n",
    "x_age = df.age_of_house\n",
    "df[\"scale_age_of_house\"] = (x_age - x_age.min()) / (x_age.max() - x_age.min())\n",
    "df[\"log_sqft_living\"] = np.log(df.sqft_living)\n",
    "df[\"log_sqft_lot\"] = np.log(df.sqft_lot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unneeded columns including the first colums of 1-hot encoded variables\n",
    "df_clean = df.drop(columns = ['id', 'date', 'bedrooms', 'bathrooms', 'sqft_living',\n",
    "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
    "       'lat', 'long', 'sqft_living15', 'sqft_lot15', 'age_of_house', \n",
    "       'upstairs_as_percent_of_house','zipcode_rank', 'zipcode_recode', \n",
    "       'bath_bin', 'bed_bin', 'BED_(0, 2]', 'BATH_(0, 2]', 'condition_bin', \n",
    "       'COND_(0, 1]', 'floor_bin', 'FLOORS_(0, 1]', 'zip_bin', 'view_bin', \n",
    "       'VIEW_(0, 1]', 'grade_bin', 'GRADE_(1, 3]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove price outliers\n",
    "df_clean = df_clean[df_clean.price < 7000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.593</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.592</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1120.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 31 May 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:14:13</td>     <th>  Log-Likelihood:    </th> <td>-2.9732e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21595</td>      <th>  AIC:               </th>  <td>5.947e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21566</td>      <th>  BIC:               </th>  <td>5.949e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    28</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>basement</th>           <td>-3.681e+06</td> <td> 2.41e+05</td> <td>  -15.279</td> <td> 0.000</td> <td>-4.15e+06</td> <td>-3.21e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>renovated</th>          <td> 5.413e+04</td> <td> 9124.851</td> <td>    5.932</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  7.2e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_per_bed</th>       <td>  1.02e+05</td> <td> 1.28e+04</td> <td>    7.946</td> <td> 0.000</td> <td> 7.69e+04</td> <td> 1.27e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BED_(2, 3]</th>         <td>-6.627e+04</td> <td> 6073.926</td> <td>  -10.911</td> <td> 0.000</td> <td>-7.82e+04</td> <td>-5.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BED_(3, 5]</th>         <td>-7.297e+04</td> <td> 8418.807</td> <td>   -8.667</td> <td> 0.000</td> <td>-8.95e+04</td> <td>-5.65e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BED_(5, 33]</th>        <td>-1.167e+05</td> <td> 1.66e+04</td> <td>   -7.043</td> <td> 0.000</td> <td>-1.49e+05</td> <td>-8.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BATH_(2, 4]</th>        <td>-2.841e+04</td> <td> 5566.929</td> <td>   -5.103</td> <td> 0.000</td> <td>-3.93e+04</td> <td>-1.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BATH_(4, 8]</th>        <td> 4.384e+05</td> <td> 1.74e+04</td> <td>   25.238</td> <td> 0.000</td> <td> 4.04e+05</td> <td> 4.72e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(1, 2]</th>        <td> 6.617e+04</td> <td> 4.65e+04</td> <td>    1.424</td> <td> 0.154</td> <td>-2.49e+04</td> <td> 1.57e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(2, 3]</th>        <td> 8.475e+04</td> <td> 4.31e+04</td> <td>    1.965</td> <td> 0.049</td> <td>  225.486</td> <td> 1.69e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(3, 4]</th>        <td> 9.691e+04</td> <td> 4.31e+04</td> <td>    2.247</td> <td> 0.025</td> <td> 1.24e+04</td> <td> 1.81e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(4, 5]</th>        <td> 1.435e+05</td> <td> 4.34e+04</td> <td>    3.307</td> <td> 0.001</td> <td> 5.85e+04</td> <td> 2.29e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLOORS_(1, 2]</th>      <td> 2.148e+04</td> <td> 3946.692</td> <td>    5.444</td> <td> 0.000</td> <td> 1.37e+04</td> <td> 2.92e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLOORS_(2, 3]</th>      <td>  1.43e+05</td> <td> 9660.350</td> <td>   14.798</td> <td> 0.000</td> <td> 1.24e+05</td> <td> 1.62e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLOORS_(3, 4]</th>      <td> 2.053e+05</td> <td> 8.76e+04</td> <td>    2.344</td> <td> 0.019</td> <td> 3.36e+04</td> <td> 3.77e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZIP_(0, 1]</th>         <td> -245.5383</td> <td> 4815.518</td> <td>   -0.051</td> <td> 0.959</td> <td>-9684.309</td> <td> 9193.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZIP_(1, 2]</th>         <td>-4335.7065</td> <td> 5037.513</td> <td>   -0.861</td> <td> 0.389</td> <td>-1.42e+04</td> <td> 5538.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZIP_(2, 3]</th>         <td>-1.246e+04</td> <td> 7850.836</td> <td>   -1.587</td> <td> 0.112</td> <td>-2.78e+04</td> <td> 2927.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(1, 2]</th>        <td> 6.817e+04</td> <td> 7827.171</td> <td>    8.710</td> <td> 0.000</td> <td> 5.28e+04</td> <td> 8.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(2, 3]</th>        <td> 1.525e+05</td> <td> 1.06e+04</td> <td>   14.337</td> <td> 0.000</td> <td> 1.32e+05</td> <td> 1.73e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(3, 4]</th>        <td> 5.137e+05</td> <td> 1.35e+04</td> <td>   38.104</td> <td> 0.000</td> <td> 4.87e+05</td> <td>  5.4e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(4, 5]</th>        <td>   1.7e-08</td> <td> 7.93e-09</td> <td>    2.143</td> <td> 0.032</td> <td> 1.45e-09</td> <td> 3.25e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRADE_(3, 7]</th>       <td> -8.45e+04</td> <td> 2.31e+05</td> <td>   -0.366</td> <td> 0.715</td> <td>-5.37e+05</td> <td> 3.68e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRADE_(7, 11]</th>      <td> 2.106e+04</td> <td> 2.31e+05</td> <td>    0.091</td> <td> 0.927</td> <td>-4.32e+05</td> <td> 4.74e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRADE_(11, 13]</th>     <td>  1.01e+06</td> <td> 2.32e+05</td> <td>    4.346</td> <td> 0.000</td> <td> 5.55e+05</td> <td> 1.47e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_sqft_living15</th>  <td> 2.184e+05</td> <td> 7896.729</td> <td>   27.656</td> <td> 0.000</td> <td> 2.03e+05</td> <td> 2.34e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_sqft_lot15</th>     <td>-1.636e+04</td> <td> 4985.585</td> <td>   -3.282</td> <td> 0.001</td> <td>-2.61e+04</td> <td>-6591.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale_age_of_house</th> <td> 3.068e+05</td> <td> 8724.034</td> <td>   35.169</td> <td> 0.000</td> <td>  2.9e+05</td> <td> 3.24e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_sqft_living</th>    <td> 3.492e+05</td> <td> 7932.288</td> <td>   44.017</td> <td> 0.000</td> <td> 3.34e+05</td> <td> 3.65e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_sqft_lot</th>       <td>-1.349e+04</td> <td> 4525.209</td> <td>   -2.981</td> <td> 0.003</td> <td>-2.24e+04</td> <td>-4620.277</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12545.791</td> <th>  Durbin-Watson:     </th>  <td>   1.978</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>319456.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.316</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>21.264</td>   <th>  Cond. No.          </th>  <td>1.00e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.98e-26. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.593\n",
       "Model:                            OLS   Adj. R-squared:                  0.592\n",
       "Method:                 Least Squares   F-statistic:                     1120.\n",
       "Date:                Fri, 31 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        18:14:13   Log-Likelihood:            -2.9732e+05\n",
       "No. Observations:               21595   AIC:                         5.947e+05\n",
       "Df Residuals:                   21566   BIC:                         5.949e+05\n",
       "Df Model:                          28                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "basement           -3.681e+06   2.41e+05    -15.279      0.000   -4.15e+06   -3.21e+06\n",
       "renovated           5.413e+04   9124.851      5.932      0.000    3.62e+04     7.2e+04\n",
       "bath_per_bed         1.02e+05   1.28e+04      7.946      0.000    7.69e+04    1.27e+05\n",
       "BED_(2, 3]         -6.627e+04   6073.926    -10.911      0.000   -7.82e+04   -5.44e+04\n",
       "BED_(3, 5]         -7.297e+04   8418.807     -8.667      0.000   -8.95e+04   -5.65e+04\n",
       "BED_(5, 33]        -1.167e+05   1.66e+04     -7.043      0.000   -1.49e+05   -8.42e+04\n",
       "BATH_(2, 4]        -2.841e+04   5566.929     -5.103      0.000   -3.93e+04   -1.75e+04\n",
       "BATH_(4, 8]         4.384e+05   1.74e+04     25.238      0.000    4.04e+05    4.72e+05\n",
       "COND_(1, 2]         6.617e+04   4.65e+04      1.424      0.154   -2.49e+04    1.57e+05\n",
       "COND_(2, 3]         8.475e+04   4.31e+04      1.965      0.049     225.486    1.69e+05\n",
       "COND_(3, 4]         9.691e+04   4.31e+04      2.247      0.025    1.24e+04    1.81e+05\n",
       "COND_(4, 5]         1.435e+05   4.34e+04      3.307      0.001    5.85e+04    2.29e+05\n",
       "FLOORS_(1, 2]       2.148e+04   3946.692      5.444      0.000    1.37e+04    2.92e+04\n",
       "FLOORS_(2, 3]        1.43e+05   9660.350     14.798      0.000    1.24e+05    1.62e+05\n",
       "FLOORS_(3, 4]       2.053e+05   8.76e+04      2.344      0.019    3.36e+04    3.77e+05\n",
       "ZIP_(0, 1]          -245.5383   4815.518     -0.051      0.959   -9684.309    9193.233\n",
       "ZIP_(1, 2]         -4335.7065   5037.513     -0.861      0.389   -1.42e+04    5538.192\n",
       "ZIP_(2, 3]         -1.246e+04   7850.836     -1.587      0.112   -2.78e+04    2927.642\n",
       "VIEW_(1, 2]         6.817e+04   7827.171      8.710      0.000    5.28e+04    8.35e+04\n",
       "VIEW_(2, 3]         1.525e+05   1.06e+04     14.337      0.000    1.32e+05    1.73e+05\n",
       "VIEW_(3, 4]         5.137e+05   1.35e+04     38.104      0.000    4.87e+05     5.4e+05\n",
       "VIEW_(4, 5]           1.7e-08   7.93e-09      2.143      0.032    1.45e-09    3.25e-08\n",
       "GRADE_(3, 7]        -8.45e+04   2.31e+05     -0.366      0.715   -5.37e+05    3.68e+05\n",
       "GRADE_(7, 11]       2.106e+04   2.31e+05      0.091      0.927   -4.32e+05    4.74e+05\n",
       "GRADE_(11, 13]       1.01e+06   2.32e+05      4.346      0.000    5.55e+05    1.47e+06\n",
       "log_sqft_living15   2.184e+05   7896.729     27.656      0.000    2.03e+05    2.34e+05\n",
       "log_sqft_lot15     -1.636e+04   4985.585     -3.282      0.001   -2.61e+04   -6591.247\n",
       "scale_age_of_house  3.068e+05   8724.034     35.169      0.000     2.9e+05    3.24e+05\n",
       "log_sqft_living     3.492e+05   7932.288     44.017      0.000    3.34e+05    3.65e+05\n",
       "log_sqft_lot       -1.349e+04   4525.209     -2.981      0.003   -2.24e+04   -4620.277\n",
       "==============================================================================\n",
       "Omnibus:                    12545.791   Durbin-Watson:                   1.978\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           319456.464\n",
       "Skew:                           2.316   Prob(JB):                         0.00\n",
       "Kurtosis:                      21.264   Cond. No.                     1.00e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.98e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare for modeling 1\n",
    "features = df_clean.drop(columns = \"price\")\n",
    "target = df_clean[\"price\"]\n",
    "X1 = features\n",
    "y1 = target\n",
    "\n",
    "#1st Model\n",
    "import statsmodels.api as sm\n",
    "X_int_sm1 = sm.add_constant(X1)\n",
    "model1 = sm.OLS(y1.astype(float), X_int_sm1.astype(float)).fit()\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.578</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.578</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1137.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 31 May 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:59:43</td>     <th>  Log-Likelihood:    </th> <td>-2.9769e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21595</td>      <th>  AIC:               </th>  <td>5.954e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21568</td>      <th>  BIC:               </th>  <td>5.957e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    26</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>-2.758e+06</td> <td> 2.43e+05</td> <td>  -11.365</td> <td> 0.000</td> <td>-3.23e+06</td> <td>-2.28e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>renovated</th>          <td> 4.159e+04</td> <td> 9268.135</td> <td>    4.487</td> <td> 0.000</td> <td> 2.34e+04</td> <td> 5.98e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_per_bed</th>       <td> 8.903e+04</td> <td> 1.31e+04</td> <td>    6.821</td> <td> 0.000</td> <td> 6.34e+04</td> <td> 1.15e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BED_(2, 3]</th>         <td>-7.663e+04</td> <td> 6168.685</td> <td>  -12.422</td> <td> 0.000</td> <td>-8.87e+04</td> <td>-6.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BED_(3, 5]</th>         <td> -8.46e+04</td> <td> 8554.717</td> <td>   -9.889</td> <td> 0.000</td> <td>-1.01e+05</td> <td>-6.78e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BED_(5, 33]</th>        <td>-1.533e+05</td> <td> 1.68e+04</td> <td>   -9.127</td> <td> 0.000</td> <td>-1.86e+05</td> <td> -1.2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BATH_(2, 4]</th>        <td>-1.816e+04</td> <td> 5651.980</td> <td>   -3.213</td> <td> 0.001</td> <td>-2.92e+04</td> <td>-7079.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BATH_(4, 8]</th>        <td> 4.426e+05</td> <td> 1.77e+04</td> <td>   25.041</td> <td> 0.000</td> <td> 4.08e+05</td> <td> 4.77e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(1, 2]</th>        <td> 2.366e+04</td> <td> 4.72e+04</td> <td>    0.501</td> <td> 0.616</td> <td>-6.89e+04</td> <td> 1.16e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(2, 3]</th>        <td> 4.301e+04</td> <td> 4.38e+04</td> <td>    0.981</td> <td> 0.327</td> <td>-4.29e+04</td> <td> 1.29e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(3, 4]</th>        <td> 5.282e+04</td> <td> 4.38e+04</td> <td>    1.205</td> <td> 0.228</td> <td>-3.31e+04</td> <td> 1.39e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(4, 5]</th>        <td> 9.306e+04</td> <td> 4.41e+04</td> <td>    2.110</td> <td> 0.035</td> <td> 6628.452</td> <td> 1.79e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLOORS_(1, 2]</th>      <td> 2.266e+04</td> <td> 4012.936</td> <td>    5.646</td> <td> 0.000</td> <td> 1.48e+04</td> <td> 3.05e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLOORS_(2, 3]</th>      <td> 1.211e+05</td> <td> 9781.771</td> <td>   12.378</td> <td> 0.000</td> <td> 1.02e+05</td> <td>  1.4e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLOORS_(3, 4]</th>      <td> 1.769e+05</td> <td> 8.91e+04</td> <td>    1.986</td> <td> 0.047</td> <td> 2304.291</td> <td> 3.52e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZIP_(0, 1]</th>         <td> 1779.6280</td> <td> 4899.351</td> <td>    0.363</td> <td> 0.716</td> <td>-7823.462</td> <td> 1.14e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZIP_(1, 2]</th>         <td>-4330.7444</td> <td> 5125.707</td> <td>   -0.845</td> <td> 0.398</td> <td>-1.44e+04</td> <td> 5716.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZIP_(2, 3]</th>         <td>-1.097e+04</td> <td> 7988.046</td> <td>   -1.373</td> <td> 0.170</td> <td>-2.66e+04</td> <td> 4686.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(1, 2]</th>        <td> 8.486e+04</td> <td> 7940.742</td> <td>   10.687</td> <td> 0.000</td> <td> 6.93e+04</td> <td>    1e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(2, 3]</th>        <td>  1.75e+05</td> <td> 1.08e+04</td> <td>   16.215</td> <td> 0.000</td> <td> 1.54e+05</td> <td> 1.96e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(3, 4]</th>        <td> 5.379e+05</td> <td> 1.37e+04</td> <td>   39.313</td> <td> 0.000</td> <td> 5.11e+05</td> <td> 5.65e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRADE_(3, 7]</th>       <td>-1.479e+05</td> <td> 2.35e+05</td> <td>   -0.629</td> <td> 0.529</td> <td>-6.09e+05</td> <td> 3.13e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRADE_(7, 11]</th>      <td>-1.536e+04</td> <td> 2.35e+05</td> <td>   -0.065</td> <td> 0.948</td> <td>-4.76e+05</td> <td> 4.46e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRADE_(11, 13]</th>     <td> 9.957e+05</td> <td> 2.37e+05</td> <td>    4.209</td> <td> 0.000</td> <td> 5.32e+05</td> <td> 1.46e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale_age_of_house</th> <td> 2.956e+05</td> <td> 8833.694</td> <td>   33.458</td> <td> 0.000</td> <td> 2.78e+05</td> <td> 3.13e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_sqft_living</th>    <td>  4.42e+05</td> <td> 7312.312</td> <td>   60.452</td> <td> 0.000</td> <td> 4.28e+05</td> <td> 4.56e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_sqft_lot</th>       <td>-1.517e+04</td> <td> 2091.430</td> <td>   -7.255</td> <td> 0.000</td> <td>-1.93e+04</td> <td>-1.11e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12233.677</td> <th>  Durbin-Watson:     </th>  <td>   1.977</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>290691.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.256</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>20.398</td>   <th>  Cond. No.          </th>  <td>3.51e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.51e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.578\n",
       "Model:                            OLS   Adj. R-squared:                  0.578\n",
       "Method:                 Least Squares   F-statistic:                     1137.\n",
       "Date:                Fri, 31 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        17:59:43   Log-Likelihood:            -2.9769e+05\n",
       "No. Observations:               21595   AIC:                         5.954e+05\n",
       "Df Residuals:                   21568   BIC:                         5.957e+05\n",
       "Df Model:                          26                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const              -2.758e+06   2.43e+05    -11.365      0.000   -3.23e+06   -2.28e+06\n",
       "renovated           4.159e+04   9268.135      4.487      0.000    2.34e+04    5.98e+04\n",
       "bath_per_bed        8.903e+04   1.31e+04      6.821      0.000    6.34e+04    1.15e+05\n",
       "BED_(2, 3]         -7.663e+04   6168.685    -12.422      0.000   -8.87e+04   -6.45e+04\n",
       "BED_(3, 5]          -8.46e+04   8554.717     -9.889      0.000   -1.01e+05   -6.78e+04\n",
       "BED_(5, 33]        -1.533e+05   1.68e+04     -9.127      0.000   -1.86e+05    -1.2e+05\n",
       "BATH_(2, 4]        -1.816e+04   5651.980     -3.213      0.001   -2.92e+04   -7079.156\n",
       "BATH_(4, 8]         4.426e+05   1.77e+04     25.041      0.000    4.08e+05    4.77e+05\n",
       "COND_(1, 2]         2.366e+04   4.72e+04      0.501      0.616   -6.89e+04    1.16e+05\n",
       "COND_(2, 3]         4.301e+04   4.38e+04      0.981      0.327   -4.29e+04    1.29e+05\n",
       "COND_(3, 4]         5.282e+04   4.38e+04      1.205      0.228   -3.31e+04    1.39e+05\n",
       "COND_(4, 5]         9.306e+04   4.41e+04      2.110      0.035    6628.452    1.79e+05\n",
       "FLOORS_(1, 2]       2.266e+04   4012.936      5.646      0.000    1.48e+04    3.05e+04\n",
       "FLOORS_(2, 3]       1.211e+05   9781.771     12.378      0.000    1.02e+05     1.4e+05\n",
       "FLOORS_(3, 4]       1.769e+05   8.91e+04      1.986      0.047    2304.291    3.52e+05\n",
       "ZIP_(0, 1]          1779.6280   4899.351      0.363      0.716   -7823.462    1.14e+04\n",
       "ZIP_(1, 2]         -4330.7444   5125.707     -0.845      0.398   -1.44e+04    5716.020\n",
       "ZIP_(2, 3]         -1.097e+04   7988.046     -1.373      0.170   -2.66e+04    4686.064\n",
       "VIEW_(1, 2]         8.486e+04   7940.742     10.687      0.000    6.93e+04       1e+05\n",
       "VIEW_(2, 3]          1.75e+05   1.08e+04     16.215      0.000    1.54e+05    1.96e+05\n",
       "VIEW_(3, 4]         5.379e+05   1.37e+04     39.313      0.000    5.11e+05    5.65e+05\n",
       "GRADE_(3, 7]       -1.479e+05   2.35e+05     -0.629      0.529   -6.09e+05    3.13e+05\n",
       "GRADE_(7, 11]      -1.536e+04   2.35e+05     -0.065      0.948   -4.76e+05    4.46e+05\n",
       "GRADE_(11, 13]      9.957e+05   2.37e+05      4.209      0.000    5.32e+05    1.46e+06\n",
       "scale_age_of_house  2.956e+05   8833.694     33.458      0.000    2.78e+05    3.13e+05\n",
       "log_sqft_living      4.42e+05   7312.312     60.452      0.000    4.28e+05    4.56e+05\n",
       "log_sqft_lot       -1.517e+04   2091.430     -7.255      0.000   -1.93e+04   -1.11e+04\n",
       "==============================================================================\n",
       "Omnibus:                    12233.677   Durbin-Watson:                   1.977\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           290691.836\n",
       "Skew:                           2.256   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.398   Cond. No.                     3.51e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.51e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare for modeling 2\n",
    "features2 = features.drop(columns = [\"basement\", \"VIEW_(4, 5]\", \"log_sqft_living15\", \"log_sqft_lot15\"])\n",
    "target2 = df_clean[\"price\"]\n",
    "X2 = features2\n",
    "y2 = target2\n",
    "\n",
    "#1st Model\n",
    "import statsmodels.api as sm\n",
    "X_int_sm2 = sm.add_constant(X2)\n",
    "model2 = sm.OLS(y2.astype(float), X_int_sm2.astype(float)).fit()\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squarred Error1: 54516557076.60007\n",
      "Test Mean Squarred Error1: 48294342892.66986\n",
      "Train Mean Square Root Error1 233487.8092676362\n",
      "Test Mean Square Root Error1 219759.7390166585\n"
     ]
    }
   ],
   "source": [
    "#Model 1.2\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.20)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train1, y_train1)\n",
    "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "y_hat_train1 = linreg.predict(X_train1)\n",
    "y_hat_test1 = linreg.predict(X_test1)\n",
    "train_residuals1 = y_hat_train1 - y_train1\n",
    "test_residuals1 = y_hat_test1 - y_test1\n",
    "from sklearn.metrics import mean_squared_error\n",
    "train_mse1 = mean_squared_error(y_train1, y_hat_train1)\n",
    "test_mse1 = mean_squared_error(y_test1, y_hat_test1)\n",
    "train_MSRE1 = np.sqrt(train_mse1)\n",
    "test_MSRE1 = np.sqrt(test_mse1)\n",
    "print('Train Mean Squarred Error1:', train_mse1)\n",
    "print('Test Mean Squarred Error1:', test_mse1)\n",
    "print('Train Mean Square Root Error1', train_MSRE1)\n",
    "print('Test Mean Square Root Error1', test_MSRE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squarred Error2: 54191761485.7682\n",
      "Test Mean Squarred Error2: 58975701049.680244\n",
      "Train Mean Square Root Error2 232791.2401396758\n",
      "Test Mean Square Root Error2 242849.13228109392\n"
     ]
    }
   ],
   "source": [
    "#Model 2.2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.20)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train2, y_train2)\n",
    "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "y_hat_train2 = linreg.predict(X_train2)\n",
    "y_hat_test2 = linreg.predict(X_test2)\n",
    "train_residuals2 = y_hat_train2 - y_train2\n",
    "test_residuals2 = y_hat_test2 - y_test2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "train_mse2 = mean_squared_error(y_train2, y_hat_train2)\n",
    "test_mse2 = mean_squared_error(y_test2, y_hat_test2)\n",
    "train_MSRE2 = np.sqrt(train_mse2)\n",
    "test_MSRE2 = np.sqrt(test_mse2)\n",
    "print('Train Mean Squarred Error2:', train_mse2)\n",
    "print('Test Mean Squarred Error2:', test_mse2)\n",
    "print('Train Mean Square Root Error2', train_MSRE2)\n",
    "print('Test Mean Square Root Error2', test_MSRE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.62930429e+15, 2.30137459e+05, 2.19539322e+05, 2.23039033e+05,\n",
       "       2.51333551e+05])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross_Val Model 1.3\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results1 = cross_val_score(linreg, X1, y1, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "np.sqrt(-1*(cv_5_results1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.53738082e+16, 2.35357359e+05, 2.25014163e+05, 2.28820582e+05,\n",
       "       2.49074069e+05])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results2 = cross_val_score(linreg, X2, y2, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "np.sqrt(-1*(cv_5_results2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
