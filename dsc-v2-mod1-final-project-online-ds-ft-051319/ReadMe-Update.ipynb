{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kings County Data\n",
    "\n",
    "We were given a dataset regarding housing prices in Kings County. Our task was to create a model that predicts selling price of a house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Import and Clean Data\n",
    "\n",
    "After importing the needed packages and exploring the data, it was clear that cleaning was needed. Specifically, there were placeholder symbols in some columns, some columns were the wrong data type and some had NaN values that needed to be replaced. After taking care of these things, there were features to engineer. In this case, I created an value for the age of the house, how much of the square feet was not in the basement, bathrooms per bedroom, and a boolean value for whether the house had a basement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sqft_basement\"].replace(to_replace=\"?\", value=\"0.0\", inplace=True) #fix placeholders\n",
    "df[\"sqft_basement\"] = df[\"sqft_basement\"].astype(float, inplace=True) #reassign to float\n",
    "df[\"basement\"] = df[\"sqft_basement\"].apply(lambda x: False if x == 0.0 else True) #create a boolean variable\n",
    "df[\"yr_renovated\"].fillna(value = 0) #deal with missing data\n",
    "df[\"renovated\"] = df[\"yr_renovated\"].map(lambda x: x > 0, True) #boolean feature\n",
    "df[\"age_of_house\"] = 2019 - df[\"yr_built\"] #engineer feature\n",
    "df[\"upstairs_as_percent_of_house\"] = (df[\"sqft_living\"] - df[\"sqft_basement\"]) / df[\"sqft_living\"] #new feature\n",
    "df[\"bath_per_bed\"] = df[\"bathrooms\"] / df[\"bedrooms\"] #new feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Coding Was Needed\n",
    "\n",
    "At this point I still needed a way to deal with zipcodes and I also needed a way to create 1 hot encoding for ordinal and categorical variables. For the zipcode data, I did outside research and grouped the zipcodes by high, midhigh, and mid average income for the area. Keep in mind, the mid is still a large average income as it is a wealthy area on the whole.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating helpful lists\n",
    "high_price_zipcodes = [98039, 98040, 98004, 98112]\n",
    "midhigh_price_zipcodes = [98075, 98033, 98074, 98053, 98121, 98006, 98199]\n",
    "mid_price_zipcodes = [98105, 98065, 98177, 98005, 98052, 98029, 98119, 98027 ,98072]\n",
    "top_20_zipcodes = high_price_zipcodes + midhigh_price_zipcodes + mid_price_zipcodes\n",
    "\n",
    "#creating a zipcode rank feature\n",
    "zipcode_rank = []\n",
    "\n",
    "for zipcode in df.zipcode:\n",
    "    if zipcode in set(high_price_zipcodes):\n",
    "        zipcode_rank.append(\"high\")        \n",
    "for zipcode in df.zipcode:\n",
    "    if zipcode in set(midhigh_price_zipcodes):\n",
    "        zipcode_rank.append(\"midhigh\")       \n",
    "for zipcode in df.zipcode:\n",
    "    if zipcode in set(mid_price_zipcodes):\n",
    "        zipcode_rank.append(\"mid\")\n",
    "for zipcode in df.zipcode:\n",
    "    if zipcode not in set(top_20_zipcodes):\n",
    "        zipcode_rank.append(\"other\")\n",
    "\n",
    "df[\"zipcode_rank\"] = zipcode_rank\n",
    "\n",
    "#recoding for final transform\n",
    "zipcode_recode = []\n",
    "for i in df[\"zipcode_rank\"]:\n",
    "    if i == \"high\":\n",
    "        zipcode_recode.append(3)\n",
    "    elif i == \"midhigh\":\n",
    "        zipcode_recode.append(2)\n",
    "    elif i == \"mid\":\n",
    "        zipcode_recode.append(1)\n",
    "    else:\n",
    "        zipcode_recode.append(0)\n",
    "df[\"zipcode_recode\"] = zipcode_recode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then created the 1 hot encoding columns for all ordinal and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dummy variables\n",
    "\n",
    "bathroom_bins = [0, 2, 4, 8]\n",
    "df[\"bath_bin\"] = pd.cut(df[\"bathrooms\"], bathroom_bins)\n",
    "df.bath_bin.value_counts()\n",
    "\n",
    "bedroom_bins = [0, 2, 3, 5, 33]\n",
    "df[\"bed_bin\"] = pd.cut(df[\"bedrooms\"], bedroom_bins)\n",
    "df.bed_bin.value_counts()\n",
    "\n",
    "bed_dummy = pd.get_dummies(df.bed_bin, prefix=\"BED\")\n",
    "bath_dummy = pd.get_dummies(df.bath_bin, prefix=\"BATH\")\n",
    "df = pd.concat([df, bed_dummy, bath_dummy], axis=1)\n",
    "\n",
    "condition_bin = [0, 1, 2, 3, 4, 5]\n",
    "df[\"condition_bin\"] = pd.cut(df[\"condition\"], condition_bin)\n",
    "condition_dummy = pd.get_dummies(df.condition_bin, prefix=\"COND\")\n",
    "df = pd.concat([df, condition_dummy], axis=1)\n",
    "\n",
    "floor_bins = [0, 1, 2, 3, 4]\n",
    "df[\"floor_bin\"] = pd.cut(df[\"floors\"], floor_bins)\n",
    "floor_dummy = pd.get_dummies(df.floor_bin, prefix=\"FLOORS\")\n",
    "df = pd.concat([df, floor_dummy], axis=1)\n",
    "\n",
    "zip_bin = [0, 1, 2, 3]\n",
    "df[\"zip_bin\"] = pd.cut(df[\"zipcode_recode\"], zip_bin)\n",
    "zip_dummy = pd.get_dummies(df.zip_bin, prefix=\"ZIP\")\n",
    "df = pd.concat([df, zip_dummy], axis=1)\n",
    "\n",
    "view_bins = [0, 1, 2, 3, 4, 5]\n",
    "df[\"view_bin\"] = pd.cut(df[\"view\"], view_bins)\n",
    "view_dummy = pd.get_dummies(df.view_bin, prefix=\"VIEW\")\n",
    "df = pd.concat([df, view_dummy], axis=1)\n",
    "\n",
    "grade_bins = [1, 3, 7, 11, 13]\n",
    "df[\"grade_bin\"] = pd.cut(df[\"grade\"], grade_bins)\n",
    "grade_dummy = pd.get_dummies(df.grade_bin, prefix=\"GRADE\")\n",
    "df = pd.concat([df, grade_dummy], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These Continuous Variables Aren't Normal\n",
    "\n",
    "At this point we have all categorical and orginal variables recoded and now we need to perform transforms on the continuous data to help normalize it. To do this i used log transforms on all data except the age of the house. I was able to use min/max scaling for age of the house for a better fit for normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable transforms for normality\n",
    "\n",
    "df[\"log_sqft_living15\"] = np.log(df.sqft_living15)\n",
    "df['log_sqft_lot15'] = np.log(df.sqft_lot15)\n",
    "x_age = df.age_of_house\n",
    "df[\"scale_age_of_house\"] = (x_age - x_age.min()) / (x_age.max() - x_age.min())\n",
    "df[\"log_sqft_living\"] = np.log(df.sqft_living)\n",
    "df[\"log_sqft_lot\"] = np.log(df.sqft_lot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the Columns Like They Are Hot\n",
    "\n",
    "Our data frame is now much larger than it needs to be. First of all, we must drop the first column of all 1 hot encoding variables to prevent multicolinearity as well as the initial column the data was encoded from. Then we need to drop other colums that show high degree of multicolinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unneeded columns including the first colums of 1-hot encoded variables\n",
    "df_clean = df.drop(columns = ['id', 'date', 'bedrooms', 'bathrooms', 'sqft_living',\n",
    "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
    "       'lat', 'long', 'sqft_living15', 'sqft_lot15', 'age_of_house', \n",
    "       'upstairs_as_percent_of_house','zipcode_rank', 'zipcode_recode', \n",
    "       'bath_bin', 'bed_bin', 'BED_(0, 2]', 'BATH_(0, 2]', 'condition_bin', \n",
    "       'COND_(0, 1]', 'floor_bin', 'FLOORS_(0, 1]', 'zip_bin', 'view_bin', \n",
    "       'VIEW_(0, 1]', 'grade_bin', 'GRADE_(1, 3]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers for Better Modeling\n",
    "\n",
    "Now we need to remove the outliers, create and verify the model. First I removed all houses over 7 million dollars. Then the appropriate libraries for modeling were imported and two models were created. The first used all of the remaining columns of the data frame. The second removed a few variables that were on the boarder of our cuttoff for multicolinearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove price outliers\n",
    "df_clean = df_clean[df_clean.price < 7000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.593</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.592</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1120.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 31 May 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:14:13</td>     <th>  Log-Likelihood:    </th> <td>-2.9732e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21595</td>      <th>  AIC:               </th>  <td>5.947e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21566</td>      <th>  BIC:               </th>  <td>5.949e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    28</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>basement</th>           <td>-3.681e+06</td> <td> 2.41e+05</td> <td>  -15.279</td> <td> 0.000</td> <td>-4.15e+06</td> <td>-3.21e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>renovated</th>          <td> 5.413e+04</td> <td> 9124.851</td> <td>    5.932</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  7.2e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_per_bed</th>       <td>  1.02e+05</td> <td> 1.28e+04</td> <td>    7.946</td> <td> 0.000</td> <td> 7.69e+04</td> <td> 1.27e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BED_(2, 3]</th>         <td>-6.627e+04</td> <td> 6073.926</td> <td>  -10.911</td> <td> 0.000</td> <td>-7.82e+04</td> <td>-5.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BED_(3, 5]</th>         <td>-7.297e+04</td> <td> 8418.807</td> <td>   -8.667</td> <td> 0.000</td> <td>-8.95e+04</td> <td>-5.65e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BED_(5, 33]</th>        <td>-1.167e+05</td> <td> 1.66e+04</td> <td>   -7.043</td> <td> 0.000</td> <td>-1.49e+05</td> <td>-8.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BATH_(2, 4]</th>        <td>-2.841e+04</td> <td> 5566.929</td> <td>   -5.103</td> <td> 0.000</td> <td>-3.93e+04</td> <td>-1.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BATH_(4, 8]</th>        <td> 4.384e+05</td> <td> 1.74e+04</td> <td>   25.238</td> <td> 0.000</td> <td> 4.04e+05</td> <td> 4.72e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(1, 2]</th>        <td> 6.617e+04</td> <td> 4.65e+04</td> <td>    1.424</td> <td> 0.154</td> <td>-2.49e+04</td> <td> 1.57e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(2, 3]</th>        <td> 8.475e+04</td> <td> 4.31e+04</td> <td>    1.965</td> <td> 0.049</td> <td>  225.486</td> <td> 1.69e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(3, 4]</th>        <td> 9.691e+04</td> <td> 4.31e+04</td> <td>    2.247</td> <td> 0.025</td> <td> 1.24e+04</td> <td> 1.81e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(4, 5]</th>        <td> 1.435e+05</td> <td> 4.34e+04</td> <td>    3.307</td> <td> 0.001</td> <td> 5.85e+04</td> <td> 2.29e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLOORS_(1, 2]</th>      <td> 2.148e+04</td> <td> 3946.692</td> <td>    5.444</td> <td> 0.000</td> <td> 1.37e+04</td> <td> 2.92e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLOORS_(2, 3]</th>      <td>  1.43e+05</td> <td> 9660.350</td> <td>   14.798</td> <td> 0.000</td> <td> 1.24e+05</td> <td> 1.62e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLOORS_(3, 4]</th>      <td> 2.053e+05</td> <td> 8.76e+04</td> <td>    2.344</td> <td> 0.019</td> <td> 3.36e+04</td> <td> 3.77e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZIP_(0, 1]</th>         <td> -245.5383</td> <td> 4815.518</td> <td>   -0.051</td> <td> 0.959</td> <td>-9684.309</td> <td> 9193.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZIP_(1, 2]</th>         <td>-4335.7065</td> <td> 5037.513</td> <td>   -0.861</td> <td> 0.389</td> <td>-1.42e+04</td> <td> 5538.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZIP_(2, 3]</th>         <td>-1.246e+04</td> <td> 7850.836</td> <td>   -1.587</td> <td> 0.112</td> <td>-2.78e+04</td> <td> 2927.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(1, 2]</th>        <td> 6.817e+04</td> <td> 7827.171</td> <td>    8.710</td> <td> 0.000</td> <td> 5.28e+04</td> <td> 8.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(2, 3]</th>        <td> 1.525e+05</td> <td> 1.06e+04</td> <td>   14.337</td> <td> 0.000</td> <td> 1.32e+05</td> <td> 1.73e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(3, 4]</th>        <td> 5.137e+05</td> <td> 1.35e+04</td> <td>   38.104</td> <td> 0.000</td> <td> 4.87e+05</td> <td>  5.4e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(4, 5]</th>        <td>   1.7e-08</td> <td> 7.93e-09</td> <td>    2.143</td> <td> 0.032</td> <td> 1.45e-09</td> <td> 3.25e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRADE_(3, 7]</th>       <td> -8.45e+04</td> <td> 2.31e+05</td> <td>   -0.366</td> <td> 0.715</td> <td>-5.37e+05</td> <td> 3.68e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRADE_(7, 11]</th>      <td> 2.106e+04</td> <td> 2.31e+05</td> <td>    0.091</td> <td> 0.927</td> <td>-4.32e+05</td> <td> 4.74e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRADE_(11, 13]</th>     <td>  1.01e+06</td> <td> 2.32e+05</td> <td>    4.346</td> <td> 0.000</td> <td> 5.55e+05</td> <td> 1.47e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_sqft_living15</th>  <td> 2.184e+05</td> <td> 7896.729</td> <td>   27.656</td> <td> 0.000</td> <td> 2.03e+05</td> <td> 2.34e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_sqft_lot15</th>     <td>-1.636e+04</td> <td> 4985.585</td> <td>   -3.282</td> <td> 0.001</td> <td>-2.61e+04</td> <td>-6591.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale_age_of_house</th> <td> 3.068e+05</td> <td> 8724.034</td> <td>   35.169</td> <td> 0.000</td> <td>  2.9e+05</td> <td> 3.24e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_sqft_living</th>    <td> 3.492e+05</td> <td> 7932.288</td> <td>   44.017</td> <td> 0.000</td> <td> 3.34e+05</td> <td> 3.65e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_sqft_lot</th>       <td>-1.349e+04</td> <td> 4525.209</td> <td>   -2.981</td> <td> 0.003</td> <td>-2.24e+04</td> <td>-4620.277</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12545.791</td> <th>  Durbin-Watson:     </th>  <td>   1.978</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>319456.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.316</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>21.264</td>   <th>  Cond. No.          </th>  <td>1.00e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.98e-26. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.593\n",
       "Model:                            OLS   Adj. R-squared:                  0.592\n",
       "Method:                 Least Squares   F-statistic:                     1120.\n",
       "Date:                Fri, 31 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        18:14:13   Log-Likelihood:            -2.9732e+05\n",
       "No. Observations:               21595   AIC:                         5.947e+05\n",
       "Df Residuals:                   21566   BIC:                         5.949e+05\n",
       "Df Model:                          28                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "basement           -3.681e+06   2.41e+05    -15.279      0.000   -4.15e+06   -3.21e+06\n",
       "renovated           5.413e+04   9124.851      5.932      0.000    3.62e+04     7.2e+04\n",
       "bath_per_bed         1.02e+05   1.28e+04      7.946      0.000    7.69e+04    1.27e+05\n",
       "BED_(2, 3]         -6.627e+04   6073.926    -10.911      0.000   -7.82e+04   -5.44e+04\n",
       "BED_(3, 5]         -7.297e+04   8418.807     -8.667      0.000   -8.95e+04   -5.65e+04\n",
       "BED_(5, 33]        -1.167e+05   1.66e+04     -7.043      0.000   -1.49e+05   -8.42e+04\n",
       "BATH_(2, 4]        -2.841e+04   5566.929     -5.103      0.000   -3.93e+04   -1.75e+04\n",
       "BATH_(4, 8]         4.384e+05   1.74e+04     25.238      0.000    4.04e+05    4.72e+05\n",
       "COND_(1, 2]         6.617e+04   4.65e+04      1.424      0.154   -2.49e+04    1.57e+05\n",
       "COND_(2, 3]         8.475e+04   4.31e+04      1.965      0.049     225.486    1.69e+05\n",
       "COND_(3, 4]         9.691e+04   4.31e+04      2.247      0.025    1.24e+04    1.81e+05\n",
       "COND_(4, 5]         1.435e+05   4.34e+04      3.307      0.001    5.85e+04    2.29e+05\n",
       "FLOORS_(1, 2]       2.148e+04   3946.692      5.444      0.000    1.37e+04    2.92e+04\n",
       "FLOORS_(2, 3]        1.43e+05   9660.350     14.798      0.000    1.24e+05    1.62e+05\n",
       "FLOORS_(3, 4]       2.053e+05   8.76e+04      2.344      0.019    3.36e+04    3.77e+05\n",
       "ZIP_(0, 1]          -245.5383   4815.518     -0.051      0.959   -9684.309    9193.233\n",
       "ZIP_(1, 2]         -4335.7065   5037.513     -0.861      0.389   -1.42e+04    5538.192\n",
       "ZIP_(2, 3]         -1.246e+04   7850.836     -1.587      0.112   -2.78e+04    2927.642\n",
       "VIEW_(1, 2]         6.817e+04   7827.171      8.710      0.000    5.28e+04    8.35e+04\n",
       "VIEW_(2, 3]         1.525e+05   1.06e+04     14.337      0.000    1.32e+05    1.73e+05\n",
       "VIEW_(3, 4]         5.137e+05   1.35e+04     38.104      0.000    4.87e+05     5.4e+05\n",
       "VIEW_(4, 5]           1.7e-08   7.93e-09      2.143      0.032    1.45e-09    3.25e-08\n",
       "GRADE_(3, 7]        -8.45e+04   2.31e+05     -0.366      0.715   -5.37e+05    3.68e+05\n",
       "GRADE_(7, 11]       2.106e+04   2.31e+05      0.091      0.927   -4.32e+05    4.74e+05\n",
       "GRADE_(11, 13]       1.01e+06   2.32e+05      4.346      0.000    5.55e+05    1.47e+06\n",
       "log_sqft_living15   2.184e+05   7896.729     27.656      0.000    2.03e+05    2.34e+05\n",
       "log_sqft_lot15     -1.636e+04   4985.585     -3.282      0.001   -2.61e+04   -6591.247\n",
       "scale_age_of_house  3.068e+05   8724.034     35.169      0.000     2.9e+05    3.24e+05\n",
       "log_sqft_living     3.492e+05   7932.288     44.017      0.000    3.34e+05    3.65e+05\n",
       "log_sqft_lot       -1.349e+04   4525.209     -2.981      0.003   -2.24e+04   -4620.277\n",
       "==============================================================================\n",
       "Omnibus:                    12545.791   Durbin-Watson:                   1.978\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           319456.464\n",
       "Skew:                           2.316   Prob(JB):                         0.00\n",
       "Kurtosis:                      21.264   Cond. No.                     1.00e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.98e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare for modeling 1\n",
    "features = df_clean.drop(columns = \"price\")\n",
    "target = df_clean[\"price\"]\n",
    "X1 = features\n",
    "y1 = target\n",
    "\n",
    "#1st Model\n",
    "import statsmodels.api as sm\n",
    "X_int_sm1 = sm.add_constant(X1)\n",
    "model1 = sm.OLS(y1.astype(float), X_int_sm1.astype(float)).fit()\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.578</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.578</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1137.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 31 May 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:59:43</td>     <th>  Log-Likelihood:    </th> <td>-2.9769e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21595</td>      <th>  AIC:               </th>  <td>5.954e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21568</td>      <th>  BIC:               </th>  <td>5.957e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    26</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>-2.758e+06</td> <td> 2.43e+05</td> <td>  -11.365</td> <td> 0.000</td> <td>-3.23e+06</td> <td>-2.28e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>renovated</th>          <td> 4.159e+04</td> <td> 9268.135</td> <td>    4.487</td> <td> 0.000</td> <td> 2.34e+04</td> <td> 5.98e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_per_bed</th>       <td> 8.903e+04</td> <td> 1.31e+04</td> <td>    6.821</td> <td> 0.000</td> <td> 6.34e+04</td> <td> 1.15e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BED_(2, 3]</th>         <td>-7.663e+04</td> <td> 6168.685</td> <td>  -12.422</td> <td> 0.000</td> <td>-8.87e+04</td> <td>-6.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BED_(3, 5]</th>         <td> -8.46e+04</td> <td> 8554.717</td> <td>   -9.889</td> <td> 0.000</td> <td>-1.01e+05</td> <td>-6.78e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BED_(5, 33]</th>        <td>-1.533e+05</td> <td> 1.68e+04</td> <td>   -9.127</td> <td> 0.000</td> <td>-1.86e+05</td> <td> -1.2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BATH_(2, 4]</th>        <td>-1.816e+04</td> <td> 5651.980</td> <td>   -3.213</td> <td> 0.001</td> <td>-2.92e+04</td> <td>-7079.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BATH_(4, 8]</th>        <td> 4.426e+05</td> <td> 1.77e+04</td> <td>   25.041</td> <td> 0.000</td> <td> 4.08e+05</td> <td> 4.77e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(1, 2]</th>        <td> 2.366e+04</td> <td> 4.72e+04</td> <td>    0.501</td> <td> 0.616</td> <td>-6.89e+04</td> <td> 1.16e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(2, 3]</th>        <td> 4.301e+04</td> <td> 4.38e+04</td> <td>    0.981</td> <td> 0.327</td> <td>-4.29e+04</td> <td> 1.29e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(3, 4]</th>        <td> 5.282e+04</td> <td> 4.38e+04</td> <td>    1.205</td> <td> 0.228</td> <td>-3.31e+04</td> <td> 1.39e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COND_(4, 5]</th>        <td> 9.306e+04</td> <td> 4.41e+04</td> <td>    2.110</td> <td> 0.035</td> <td> 6628.452</td> <td> 1.79e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLOORS_(1, 2]</th>      <td> 2.266e+04</td> <td> 4012.936</td> <td>    5.646</td> <td> 0.000</td> <td> 1.48e+04</td> <td> 3.05e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLOORS_(2, 3]</th>      <td> 1.211e+05</td> <td> 9781.771</td> <td>   12.378</td> <td> 0.000</td> <td> 1.02e+05</td> <td>  1.4e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLOORS_(3, 4]</th>      <td> 1.769e+05</td> <td> 8.91e+04</td> <td>    1.986</td> <td> 0.047</td> <td> 2304.291</td> <td> 3.52e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZIP_(0, 1]</th>         <td> 1779.6280</td> <td> 4899.351</td> <td>    0.363</td> <td> 0.716</td> <td>-7823.462</td> <td> 1.14e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZIP_(1, 2]</th>         <td>-4330.7444</td> <td> 5125.707</td> <td>   -0.845</td> <td> 0.398</td> <td>-1.44e+04</td> <td> 5716.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZIP_(2, 3]</th>         <td>-1.097e+04</td> <td> 7988.046</td> <td>   -1.373</td> <td> 0.170</td> <td>-2.66e+04</td> <td> 4686.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(1, 2]</th>        <td> 8.486e+04</td> <td> 7940.742</td> <td>   10.687</td> <td> 0.000</td> <td> 6.93e+04</td> <td>    1e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(2, 3]</th>        <td>  1.75e+05</td> <td> 1.08e+04</td> <td>   16.215</td> <td> 0.000</td> <td> 1.54e+05</td> <td> 1.96e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VIEW_(3, 4]</th>        <td> 5.379e+05</td> <td> 1.37e+04</td> <td>   39.313</td> <td> 0.000</td> <td> 5.11e+05</td> <td> 5.65e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRADE_(3, 7]</th>       <td>-1.479e+05</td> <td> 2.35e+05</td> <td>   -0.629</td> <td> 0.529</td> <td>-6.09e+05</td> <td> 3.13e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRADE_(7, 11]</th>      <td>-1.536e+04</td> <td> 2.35e+05</td> <td>   -0.065</td> <td> 0.948</td> <td>-4.76e+05</td> <td> 4.46e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRADE_(11, 13]</th>     <td> 9.957e+05</td> <td> 2.37e+05</td> <td>    4.209</td> <td> 0.000</td> <td> 5.32e+05</td> <td> 1.46e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale_age_of_house</th> <td> 2.956e+05</td> <td> 8833.694</td> <td>   33.458</td> <td> 0.000</td> <td> 2.78e+05</td> <td> 3.13e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_sqft_living</th>    <td>  4.42e+05</td> <td> 7312.312</td> <td>   60.452</td> <td> 0.000</td> <td> 4.28e+05</td> <td> 4.56e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_sqft_lot</th>       <td>-1.517e+04</td> <td> 2091.430</td> <td>   -7.255</td> <td> 0.000</td> <td>-1.93e+04</td> <td>-1.11e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12233.677</td> <th>  Durbin-Watson:     </th>  <td>   1.977</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>290691.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.256</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>20.398</td>   <th>  Cond. No.          </th>  <td>3.51e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.51e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.578\n",
       "Model:                            OLS   Adj. R-squared:                  0.578\n",
       "Method:                 Least Squares   F-statistic:                     1137.\n",
       "Date:                Fri, 31 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        17:59:43   Log-Likelihood:            -2.9769e+05\n",
       "No. Observations:               21595   AIC:                         5.954e+05\n",
       "Df Residuals:                   21568   BIC:                         5.957e+05\n",
       "Df Model:                          26                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const              -2.758e+06   2.43e+05    -11.365      0.000   -3.23e+06   -2.28e+06\n",
       "renovated           4.159e+04   9268.135      4.487      0.000    2.34e+04    5.98e+04\n",
       "bath_per_bed        8.903e+04   1.31e+04      6.821      0.000    6.34e+04    1.15e+05\n",
       "BED_(2, 3]         -7.663e+04   6168.685    -12.422      0.000   -8.87e+04   -6.45e+04\n",
       "BED_(3, 5]          -8.46e+04   8554.717     -9.889      0.000   -1.01e+05   -6.78e+04\n",
       "BED_(5, 33]        -1.533e+05   1.68e+04     -9.127      0.000   -1.86e+05    -1.2e+05\n",
       "BATH_(2, 4]        -1.816e+04   5651.980     -3.213      0.001   -2.92e+04   -7079.156\n",
       "BATH_(4, 8]         4.426e+05   1.77e+04     25.041      0.000    4.08e+05    4.77e+05\n",
       "COND_(1, 2]         2.366e+04   4.72e+04      0.501      0.616   -6.89e+04    1.16e+05\n",
       "COND_(2, 3]         4.301e+04   4.38e+04      0.981      0.327   -4.29e+04    1.29e+05\n",
       "COND_(3, 4]         5.282e+04   4.38e+04      1.205      0.228   -3.31e+04    1.39e+05\n",
       "COND_(4, 5]         9.306e+04   4.41e+04      2.110      0.035    6628.452    1.79e+05\n",
       "FLOORS_(1, 2]       2.266e+04   4012.936      5.646      0.000    1.48e+04    3.05e+04\n",
       "FLOORS_(2, 3]       1.211e+05   9781.771     12.378      0.000    1.02e+05     1.4e+05\n",
       "FLOORS_(3, 4]       1.769e+05   8.91e+04      1.986      0.047    2304.291    3.52e+05\n",
       "ZIP_(0, 1]          1779.6280   4899.351      0.363      0.716   -7823.462    1.14e+04\n",
       "ZIP_(1, 2]         -4330.7444   5125.707     -0.845      0.398   -1.44e+04    5716.020\n",
       "ZIP_(2, 3]         -1.097e+04   7988.046     -1.373      0.170   -2.66e+04    4686.064\n",
       "VIEW_(1, 2]         8.486e+04   7940.742     10.687      0.000    6.93e+04       1e+05\n",
       "VIEW_(2, 3]          1.75e+05   1.08e+04     16.215      0.000    1.54e+05    1.96e+05\n",
       "VIEW_(3, 4]         5.379e+05   1.37e+04     39.313      0.000    5.11e+05    5.65e+05\n",
       "GRADE_(3, 7]       -1.479e+05   2.35e+05     -0.629      0.529   -6.09e+05    3.13e+05\n",
       "GRADE_(7, 11]      -1.536e+04   2.35e+05     -0.065      0.948   -4.76e+05    4.46e+05\n",
       "GRADE_(11, 13]      9.957e+05   2.37e+05      4.209      0.000    5.32e+05    1.46e+06\n",
       "scale_age_of_house  2.956e+05   8833.694     33.458      0.000    2.78e+05    3.13e+05\n",
       "log_sqft_living      4.42e+05   7312.312     60.452      0.000    4.28e+05    4.56e+05\n",
       "log_sqft_lot       -1.517e+04   2091.430     -7.255      0.000   -1.93e+04   -1.11e+04\n",
       "==============================================================================\n",
       "Omnibus:                    12233.677   Durbin-Watson:                   1.977\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           290691.836\n",
       "Skew:                           2.256   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.398   Cond. No.                     3.51e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.51e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare for modeling 2\n",
    "features2 = features.drop(columns = [\"basement\", \"VIEW_(4, 5]\", \"log_sqft_living15\", \"log_sqft_lot15\"])\n",
    "target2 = df_clean[\"price\"]\n",
    "X2 = features2\n",
    "y2 = target2\n",
    "\n",
    "#1st Model\n",
    "import statsmodels.api as sm\n",
    "X_int_sm2 = sm.add_constant(X2)\n",
    "model2 = sm.OLS(y2.astype(float), X_int_sm2.astype(float)).fit()\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modled with Scikit Learn and MSE and MSRE Calculated\n",
    "\n",
    "I also created models with each of the two data frames with scikit learn to use the cross validation option. Then the mean squared error and the mean square root error were calulated for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squarred Error1: 54516557076.60007\n",
      "Test Mean Squarred Error1: 48294342892.66986\n",
      "Train Mean Square Root Error1 233487.8092676362\n",
      "Test Mean Square Root Error1 219759.7390166585\n"
     ]
    }
   ],
   "source": [
    "#Model 1.2\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.20)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train1, y_train1)\n",
    "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "y_hat_train1 = linreg.predict(X_train1)\n",
    "y_hat_test1 = linreg.predict(X_test1)\n",
    "train_residuals1 = y_hat_train1 - y_train1\n",
    "test_residuals1 = y_hat_test1 - y_test1\n",
    "from sklearn.metrics import mean_squared_error\n",
    "train_mse1 = mean_squared_error(y_train1, y_hat_train1)\n",
    "test_mse1 = mean_squared_error(y_test1, y_hat_test1)\n",
    "train_MSRE1 = np.sqrt(train_mse1)\n",
    "test_MSRE1 = np.sqrt(test_mse1)\n",
    "print('Train Mean Squarred Error1:', train_mse1)\n",
    "print('Test Mean Squarred Error1:', test_mse1)\n",
    "print('Train Mean Square Root Error1', train_MSRE1)\n",
    "print('Test Mean Square Root Error1', test_MSRE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squarred Error2: 54191761485.7682\n",
      "Test Mean Squarred Error2: 58975701049.680244\n",
      "Train Mean Square Root Error2 232791.2401396758\n",
      "Test Mean Square Root Error2 242849.13228109392\n"
     ]
    }
   ],
   "source": [
    "#Model 2.2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.20)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train2, y_train2)\n",
    "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "y_hat_train2 = linreg.predict(X_train2)\n",
    "y_hat_test2 = linreg.predict(X_test2)\n",
    "train_residuals2 = y_hat_train2 - y_train2\n",
    "test_residuals2 = y_hat_test2 - y_test2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "train_mse2 = mean_squared_error(y_train2, y_hat_train2)\n",
    "test_mse2 = mean_squared_error(y_test2, y_hat_test2)\n",
    "train_MSRE2 = np.sqrt(train_mse2)\n",
    "test_MSRE2 = np.sqrt(test_mse2)\n",
    "print('Train Mean Squarred Error2:', train_mse2)\n",
    "print('Test Mean Squarred Error2:', test_mse2)\n",
    "print('Train Mean Square Root Error2', train_MSRE2)\n",
    "print('Test Mean Square Root Error2', test_MSRE2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lastly V-Fold Cross Validation\n",
    "\n",
    "Here v-fold cross validation was performed and then the mean squared error was calculated for both models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.62930429e+15, 2.30137459e+05, 2.19539322e+05, 2.23039033e+05,\n",
       "       2.51333551e+05])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross_Val Model 1.3\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results1 = cross_val_score(linreg, X1, y1, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "np.sqrt(-1*(cv_5_results1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.53738082e+16, 2.35357359e+05, 2.25014163e+05, 2.28820582e+05,\n",
       "       2.49074069e+05])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results2 = cross_val_score(linreg, X2, y2, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "np.sqrt(-1*(cv_5_results2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
